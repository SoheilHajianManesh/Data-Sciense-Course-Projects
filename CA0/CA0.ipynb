{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecfbb4b0c704e67",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Web Scraping and Introductory Data Analysis\n",
    "\n",
    "Welcome to Homework 0, where we will delve into web scraping and perform an introductory data analysis. This homework will be a hands-on exercise that will help you become familiar with the process of extracting data from websites and conducting basic statistical analysis. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "By the end of this homework, you will be able to:\n",
    "\n",
    "1. Set up a Python environment with the necessary libraries for web scraping and data analysis.\n",
    "2. Write a web scraping script using Beautiful Soup and Selenium to collect data from a website.\n",
    "3. Sample from the collected dataset and compare the statistics of the sample and the population.\n",
    "   \n",
    "## Tasks\n",
    "\n",
    "1. **Environment Setup**: Install the required libraries such as Beautiful Soup, Selenium, pandas, numpy, matplotlib, and seaborn.\n",
    "\n",
    "2. **Web Scraping**: Write a script to scrape transaction data from [Etherscan.io](https://etherscan.io/txs). Use Selenium to interact with the website and Beautiful Soup to parse the HTML content.\n",
    "\n",
    "3. **Data Sampling**: Once the data is collected, create a sample from the dataset. Compare the sample statistics (mean and standard deviation) with the population statistics.\n",
    "\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "1. A Jupyter notebook with all the code and explanations.\n",
    "2. A detailed report on the findings, including the comparison of sample and population statistics.\n",
    "Note: You can include the report in your notebook.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Begin by setting up your Python environment and installing the necessary libraries. Then, proceed with the web scraping task, ensuring that you handle any potential issues such as rate limiting. Once you have the data, move on to the data sampling and statistical analysis tasks. \n",
    "\n",
    "Remember to document your process and findings in the Jupyter notebook, and to include visualizations where appropriate to illustrate your results. <br>\n",
    "Good luck, and happy scraping!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca352a49724d191",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Collection (Etherscan)\n",
    "\n",
    "In this section, we will use web scraping to gather transaction data from the Ethereum blockchain using the Etherscan block explorer. Our objective is to collect transactions from the **last 10 blocks** on Ethereum.\n",
    "\n",
    "To accomplish this task, we will employ web scraping techniques to extract the transaction data from the Etherscan website. The URL we will be targeting for our data collection is:\n",
    "\n",
    "[https://etherscan.io/txs](https://etherscan.io/txs)\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Navigate to the URL**: Use Selenium to open the Etherscan transactions page in a browser.\n",
    "\n",
    "2. **Locate the Transaction Data**: Identify the HTML elements that contain the transaction data for the specified block range.\n",
    "\n",
    "3. **Extract the Data**: Write a script to extract the transaction details e.g. Hash, Method, Block, etc.\n",
    "\n",
    "4. **Handle Pagination**: If the transactions span multiple pages, implement pagination handling to navigate through the pages and collect all relevant transaction data.\n",
    "\n",
    "5. **Store the Data**: Save the extracted transaction data into a structured format, such as a CSV file or a pandas DataFrame, for further analysis.\n",
    "\n",
    "### Considerations\n",
    "\n",
    "- **Rate Limiting**: Be mindful of the website's rate limits to avoid being blocked. Implement delays between requests if necessary.\n",
    "- **Dynamic Content**: The Etherscan website may load content dynamically. Ensure that Selenium waits for the necessary elements to load before attempting to scrape the data.\n",
    "- **Data Cleaning**: After extraction, clean the data to remove any inconsistencies or errors that may have occurred during the scraping process.\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Selenium Documentation](https://selenium-python.readthedocs.io/)\n",
    "- [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "- [Ethereum](https://ethereum.org/en/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77df2f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54fa10db-ec9e-4921-870a-50066926ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "url = \"https://etherscan.io/txs\"\n",
    "\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a242e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_html_content(driver):\n",
    "    body = driver.find_element(By.TAG_NAME,\"tbody\")\n",
    "    html_content=body.get_attribute(\"innerHTML\")\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    return soup.find_all(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c21dcae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attributes(item):\n",
    "    return {\n",
    "            \"txn Hash\": item.find(\"span\", class_=\"hash-tag\").text.strip(),\n",
    "            \"Method\": item.find(\"span\", class_=\"badge\").text.strip(),\n",
    "            \"Block\": item.find_all(\"td\")[3].text.strip(),\n",
    "            \"Age\": item.find(\"td\", class_=\"showAge\").text.strip(),\n",
    "            \"Sender\": item.find_all(\"td\")[7].text.strip(),\n",
    "            \"Receiver\": item.find_all(\"td\")[9].text.strip(),\n",
    "            \"Value\": item.find_all(\"td\")[10].text.strip(),\n",
    "            \"Txn Fee\": item.find_all(\"td\", class_=\"small text-muted showTxnFee\")[0].text.strip()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e4071214",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "page_number=0\n",
    "while(page_number<50):\n",
    "    tr=extract_html_content(driver)\n",
    "    for item in tr:    \n",
    "        all_data.append(extract_attributes(item))\n",
    "    next_page = driver.find_element(By.XPATH, '//a[@class=\"page-link px-3\" and @aria-label=\"Next\"]')  # Locate the next page link\n",
    "    next_page.click()\n",
    "    page_number+=1\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "71a07021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txn Hash</th>\n",
       "      <th>Method</th>\n",
       "      <th>Block</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sender</th>\n",
       "      <th>Receiver</th>\n",
       "      <th>Value</th>\n",
       "      <th>Txn Fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x2df34940a563dd1f022e6e3b62293c2cf132e0ac578d...</td>\n",
       "      <td>Multicall</td>\n",
       "      <td>19334785</td>\n",
       "      <td>2 mins ago</td>\n",
       "      <td>SideShift: Hot Wallet</td>\n",
       "      <td>Uniswap V3: Router 2</td>\n",
       "      <td>0 ETH</td>\n",
       "      <td>0.01304642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xa4294be099c6c523bfafe7efcb82d24210f0625e911b...</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>19334785</td>\n",
       "      <td>2 mins ago</td>\n",
       "      <td>Binance 15</td>\n",
       "      <td>Memecoin: MEME Token</td>\n",
       "      <td>0 ETH</td>\n",
       "      <td>0.00463967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x4fa60858de4c3f95dd0107786c0fefcae2759a7b1615...</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>19334785</td>\n",
       "      <td>2 mins ago</td>\n",
       "      <td>0xbd0fCcdC...7C77A5BEC</td>\n",
       "      <td>Tether: USDT Stablecoin</td>\n",
       "      <td>0 ETH</td>\n",
       "      <td>0.00569925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x395a658b684ea755f650d3ca922dc2fdb55ead12112e...</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>19334785</td>\n",
       "      <td>2 mins ago</td>\n",
       "      <td>0x808d0aeE...8c9cCDBA4</td>\n",
       "      <td>Tether: USDT Stablecoin</td>\n",
       "      <td>0 ETH</td>\n",
       "      <td>0.004159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xb253ec3a2a5de00ab0b8f9c22aac97b0132f429b1422...</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>19334785</td>\n",
       "      <td>2 mins ago</td>\n",
       "      <td>Bybit: Hot Wallet</td>\n",
       "      <td>Tether: USDT Stablecoin</td>\n",
       "      <td>0 ETH</td>\n",
       "      <td>0.00570141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>0x583659c02bb9b66e3f7a7284c6e73a76eb30f8cc3a70...</td>\n",
       "      <td>Execute F Fs Yo</td>\n",
       "      <td>19334821</td>\n",
       "      <td>5 mins ago</td>\n",
       "      <td>0x26bce6eC...27FEF3B2e</td>\n",
       "      <td>MEV Bot: 0xA69...78C</td>\n",
       "      <td>0 ETH</td>\n",
       "      <td>0.01541267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>0x3633b3a363ec6ddb0ef97292444f6b2f8f22e2c8829a...</td>\n",
       "      <td>0xa5216a1c</td>\n",
       "      <td>19334821</td>\n",
       "      <td>5 mins ago</td>\n",
       "      <td>0xfc9928F6...36785e535</td>\n",
       "      <td>0x00000000...4fd120E49</td>\n",
       "      <td>0 ETH</td>\n",
       "      <td>0.05554333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>0x9be53966ddc4420c40b938d42377d4f76b0936c98f89...</td>\n",
       "      <td>0x1d644169</td>\n",
       "      <td>19334821</td>\n",
       "      <td>5 mins ago</td>\n",
       "      <td>0xB169a7AB...6a2E5676F</td>\n",
       "      <td>0x767C8bB1...9D43C5121</td>\n",
       "      <td>0 ETH</td>\n",
       "      <td>0.0148793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>0xf8067ad1aa266fb41c8d04f936a86b4485ce91aae604...</td>\n",
       "      <td>Execute</td>\n",
       "      <td>19334821</td>\n",
       "      <td>5 mins ago</td>\n",
       "      <td>0x71b253B6...945C593db</td>\n",
       "      <td>0xF1b0475a...A8679BEdF</td>\n",
       "      <td>0.00573254 ETH</td>\n",
       "      <td>0.00287412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>0x809cc38daeacc884ad3acef8410adb17bb114b7861a3...</td>\n",
       "      <td>Swap Exact Token...</td>\n",
       "      <td>19334821</td>\n",
       "      <td>5 mins ago</td>\n",
       "      <td>0x1217678B...2C0833f6D</td>\n",
       "      <td>Uniswap V2: Router 2</td>\n",
       "      <td>0 ETH</td>\n",
       "      <td>0.01187798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1551 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               txn Hash               Method  \\\n",
       "0     0x2df34940a563dd1f022e6e3b62293c2cf132e0ac578d...            Multicall   \n",
       "1     0xa4294be099c6c523bfafe7efcb82d24210f0625e911b...             Transfer   \n",
       "2     0x4fa60858de4c3f95dd0107786c0fefcae2759a7b1615...             Transfer   \n",
       "3     0x395a658b684ea755f650d3ca922dc2fdb55ead12112e...             Transfer   \n",
       "4     0xb253ec3a2a5de00ab0b8f9c22aac97b0132f429b1422...             Transfer   \n",
       "...                                                 ...                  ...   \n",
       "2096  0x583659c02bb9b66e3f7a7284c6e73a76eb30f8cc3a70...      Execute F Fs Yo   \n",
       "2097  0x3633b3a363ec6ddb0ef97292444f6b2f8f22e2c8829a...           0xa5216a1c   \n",
       "2098  0x9be53966ddc4420c40b938d42377d4f76b0936c98f89...           0x1d644169   \n",
       "2099  0xf8067ad1aa266fb41c8d04f936a86b4485ce91aae604...              Execute   \n",
       "2100  0x809cc38daeacc884ad3acef8410adb17bb114b7861a3...  Swap Exact Token...   \n",
       "\n",
       "         Block         Age                  Sender                 Receiver  \\\n",
       "0     19334785  2 mins ago   SideShift: Hot Wallet     Uniswap V3: Router 2   \n",
       "1     19334785  2 mins ago              Binance 15     Memecoin: MEME Token   \n",
       "2     19334785  2 mins ago  0xbd0fCcdC...7C77A5BEC  Tether: USDT Stablecoin   \n",
       "3     19334785  2 mins ago  0x808d0aeE...8c9cCDBA4  Tether: USDT Stablecoin   \n",
       "4     19334785  2 mins ago       Bybit: Hot Wallet  Tether: USDT Stablecoin   \n",
       "...        ...         ...                     ...                      ...   \n",
       "2096  19334821  5 mins ago  0x26bce6eC...27FEF3B2e     MEV Bot: 0xA69...78C   \n",
       "2097  19334821  5 mins ago  0xfc9928F6...36785e535   0x00000000...4fd120E49   \n",
       "2098  19334821  5 mins ago  0xB169a7AB...6a2E5676F   0x767C8bB1...9D43C5121   \n",
       "2099  19334821  5 mins ago  0x71b253B6...945C593db   0xF1b0475a...A8679BEdF   \n",
       "2100  19334821  5 mins ago  0x1217678B...2C0833f6D     Uniswap V2: Router 2   \n",
       "\n",
       "               Value     Txn Fee  \n",
       "0              0 ETH  0.01304642  \n",
       "1              0 ETH  0.00463967  \n",
       "2              0 ETH  0.00569925  \n",
       "3              0 ETH    0.004159  \n",
       "4              0 ETH  0.00570141  \n",
       "...              ...         ...  \n",
       "2096           0 ETH  0.01541267  \n",
       "2097           0 ETH  0.05554333  \n",
       "2098           0 ETH   0.0148793  \n",
       "2099  0.00573254 ETH  0.00287412  \n",
       "2100           0 ETH  0.01187798  \n",
       "\n",
       "[1551 rows x 8 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10_blocks = df[\"Block\"].drop_duplicates().head(10)\n",
    "filtered_df = df[df[\"Block\"].isin(first_10_blocks)].drop_duplicates(subset=\"txn Hash\", keep=\"first\")\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a013b104d142cfc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Analysis\n",
    "\n",
    "Now that we have collected the transaction data from Etherscan, the next step is to perform conduct an initial analysis. This task will involve the following steps:\n",
    "\n",
    "1. **Load the Data**: Import the collected transaction data into a pandas DataFrame.\n",
    "\n",
    "2. **Data Cleaning**: Clean the data by converting data types, removing any irrelevant information, and handling **duplicate** values.\n",
    "\n",
    "3. **Statistical Analysis**: Calculate the mean and standard deviation of the population. Evaluate these statistics to understand the distribution of transaction values. The analysis and plotting will be on **Txn Fee** and **Value**.\n",
    "\n",
    "4. **Visualization**: This phase involves the creation of visual representations to aid in the analysis of transaction values. The visualizations include:\n",
    "    - A histogram for each data column, which provides a visual representation of the data distribution. The selection of bin size is crucial and should be based on the data's characteristics to ensure accurate representation. Provide an explanation on the bin size selection!\n",
    "    - A normal distribution plot fitted alongside the histogram to compare the empirical distribution of the data with the theoretical normal distribution.\n",
    "    - A box plot and a violin plot to identify outliers and provide a comprehensive view of the data's distribution.\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "The project aims to deliver the following deliverables:\n",
    "\n",
    "- A refined pandas DataFrame containing the transaction data, which has undergone thorough cleaning and is ready for analysis.\n",
    "- A simple statistical analysis evaluating the population statistics, offering insights into the distribution of transaction values and fees.\n",
    "- A set of visualizations showcasing the distribution of transaction values for the population. These visualizations include histograms, normal distribution plots, box plots, and violin plots, each serving a specific purpose in the analysis.\n",
    "\n",
    "### Getting Started\n",
    "\n",
    "The project starts with the importing of transaction data into a pandas DataFrame, setting the stage for data manipulation and analysis. Subsequent steps involve the cleaning of the data to ensure its quality and reliability. Followed by the calculation of population statistics. Finally, a series of visualizations are created to visually analyze the distribution of transaction values and fees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f481b11a08d876b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T14:02:12.152030482Z",
     "start_time": "2024-02-25T14:02:12.101846096Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87030e5e0b4fe1e6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Sampling and Analysis\n",
    "\n",
    "In this section, we will delve into the process of data sampling and perform an initial analysis on the transaction data we have collected. Our objective is to understand the distribution of transaction values by sampling the data and comparing the sample statistics with the population statistics.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Load the Data**: Import the collected transaction data into a pandas DataFrame.\n",
    "\n",
    "2. **Data Cleaning**: Clean the data by handling missing values, converting data types, and removing any irrelevant information.\n",
    "\n",
    "3. **Simple Random Sampling (SRS)**: Create a sample from the dataset using a simple random sampling method. This involves randomly selecting a subset of the data without regard to any specific characteristics of the data.\n",
    "\n",
    "4. **Stratified Sampling**: Create another sample from the dataset using a stratified sampling method. This involves dividing the data into strata based on a specific characteristic (e.g., transaction value) and then randomly selecting samples from each stratum. Explain what you have stratified the data by and why you chose this column.\n",
    "\n",
    "5. **Statistical Analysis**: Calculate the mean and standard deviation of the samples and the population. Compare these statistics to understand the distribution of transaction values.\n",
    "\n",
    "6. **Visualization**: Plot the distribution of transaction values and fees for both the samples and the population to visually compare their distributions.\n",
    "\n",
    "### Considerations\n",
    "\n",
    "- **Sample Size**: The size of the sample should be large enough to represent the population accurately but not so large that it becomes impractical to analyze.\n",
    "- **Sampling Method**: Choose the appropriate sampling method based on the characteristics of the data and the research question.\n",
    "\n",
    "Explain the above considerations in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f6becd41f9b2393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T19:36:26.333480965Z",
     "start_time": "2024-02-27T19:36:26.324023052Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
